{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2 as cv\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib.image as mpimg\r\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
    "from tensorflow.keras.applications import MobileNetV2\r\n",
    "from tensorflow.keras.layers import AveragePooling2D\r\n",
    "from tensorflow.keras.layers import Dropout\r\n",
    "from tensorflow.keras.layers import Flatten\r\n",
    "from tensorflow.keras.layers import Dense\r\n",
    "from tensorflow.keras.layers import Input\r\n",
    "from tensorflow.keras.models import Model\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\r\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\r\n",
    "from tensorflow.keras.preprocessing.image import load_img\r\n",
    "from tensorflow.keras.utils import to_categorical\r\n",
    "from sklearn.preprocessing import LabelBinarizer\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from imutils import paths\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import argparse\r\n",
    "import os\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "learning_rate = 1e-4\r\n",
    "EPOCHS = 20\r\n",
    "BS = 32"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = []\r\n",
    "labels = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "# Collection of data and its labels...\r\n",
    "\r\n",
    "Image_Paths_1 = list(paths.list_images(r\"C:\\Users\\sudha\\Desktop\\data\\with_mask\"))\r\n",
    "Image_Paths_2 = list(paths.list_images(r\"C:\\Users\\sudha\\Desktop\\data\\without_mask\"))\r\n",
    "\r\n",
    "for i in Image_Paths_1:\r\n",
    "    labels.append(\"with_mask\")\r\n",
    "for i in Image_Paths_2:\r\n",
    "    labels.append(\"without_mask\")\r\n",
    "\r\n",
    "Image_Paths = Image_Paths_1 + Image_Paths_2\r\n",
    "\r\n",
    "for image_path in Image_Paths:\r\n",
    "    image = load_img(image_path,target_size=(224,224))\r\n",
    "    image = img_to_array(image)\r\n",
    "    image = preprocess_input(image)\r\n",
    "    data.append(image)\r\n",
    "\r\n",
    "data = np.array(data, dtype=\"float32\")\r\n",
    "labels = np.array(labels)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Encoding of labels using OneHotEncoding\r\n",
    "\r\n",
    "lb = LabelBinarizer()\r\n",
    "labels = lb.fit_transform(labels)\r\n",
    "labels = to_categorical(labels)\r\n",
    "\r\n",
    "print(labels)\r\n",
    "\r\n",
    "print()\r\n",
    "\r\n",
    "print(data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#For data Augumentation\r\n",
    "aug = ImageDataGenerator(\r\n",
    "\trotation_range=20,\r\n",
    "\tzoom_range=0.15,\r\n",
    "\twidth_shift_range=0.2,\r\n",
    "\theight_shift_range=0.2,\r\n",
    "\tshear_range=0.15,\r\n",
    "\thorizontal_flip=True,\r\n",
    "\tfill_mode=\"nearest\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# train and test data split\r\n",
    "train_X,test_X,train_Y,test_Y = train_test_split(data,labels,test_size=0.2,stratify=labels,random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Contruction of model\r\n",
    "# Here we use MobilNetV2 model\r\n",
    "# We contruct the Fully Connected head by ourselves\r\n",
    "# and append it in the model\r\n",
    "\r\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\r\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)))\r\n",
    "\r\n",
    "headModel = baseModel.output\r\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\r\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\r\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\r\n",
    "headModel = Dropout(0.5)(headModel)\r\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\r\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\r\n",
    "for layer in baseModel.layers:\r\n",
    "\tlayer.trainable = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# We use adam optimzer\r\n",
    "# Then we start compiling our model\r\n",
    "\r\n",
    "print(\"compiling model...\")\r\n",
    "\r\n",
    "opt = Adam(lr=learning_rate, decay=learning_rate / EPOCHS)\r\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\r\n",
    "\tmetrics=[\"accuracy\"])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"training head...\")\r\n",
    "H = model.fit(\r\n",
    "\taug.flow(train_X, train_Y, batch_size=BS),\r\n",
    "\tsteps_per_epoch=len(train_X) // BS,\r\n",
    "\tvalidation_data=(test_X, test_Y),\r\n",
    "\tvalidation_steps=len(test_X) // BS,\r\n",
    "\tepochs=EPOCHS)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Graphical representation of our model parameters\r\n",
    "\r\n",
    "N = EPOCHS\r\n",
    "plt.style.use(\"ggplot\")\r\n",
    "plt.figure()\r\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\r\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\r\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\r\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\r\n",
    "plt.title(\"Training Loss and Accuracy\")\r\n",
    "plt.xlabel(\"Epoch #\")\r\n",
    "plt.ylabel(\"Loss/Accuracy\")\r\n",
    "plt.legend(loc=\"lower left\")\r\n",
    "plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# After training the model we start testing it using webcam \r\n",
    "# We using face detection algorithm and then predict the presence of mask using our model\r\n",
    "# If rectangle color = red, means no mask\r\n",
    "# If rectangle color = green, means there is mask\r\n",
    "# The percentage shows the confidence of the model in its prediction\r\n",
    "\r\n",
    "cap = cv.VideoCapture(0)\r\n",
    "face_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\r\n",
    "while True:\r\n",
    "    ret,frame = cap.read()\r\n",
    "    facee = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\r\n",
    "    #print(facee.shape)\r\n",
    "    facee = cv.resize(facee, (224, 224))\r\n",
    "    #print(facee.shape)\r\n",
    "    facee = img_to_array(facee)\r\n",
    "    #print(facee)\r\n",
    "    facee = preprocess_input(facee)\r\n",
    "    #print(facee)\r\n",
    "    facee = np.array(facee, dtype=\"float32\")\r\n",
    "    #print(facee.shape)\r\n",
    "    facee = facee.reshape(1,224,224,3)\r\n",
    "    preds = model.predict(facee,batch_size=BS)\r\n",
    "    [mask, withoutMask] = preds[0]\r\n",
    "    gry = cv.cvtColor(frame,cv.COLOR_BGR2GRAY)\r\n",
    "    faces = face_cascade.detectMultiScale(gry, 1.2, 5)\r\n",
    "    color = (0,0,255)\r\n",
    "    for(x,y,w,h) in faces:\r\n",
    "        l = \"mask\" if mask > withoutMask else \"No mask\"\r\n",
    "        color = (0, 255, 0) if l == \"mask\" else (0, 0, 255)\r\n",
    "        maxim = \"{}: {:.2f}%\".format(l, max(mask, withoutMask) * 100)\r\n",
    "        cv.putText(frame, maxim, (x, y-10), cv.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\r\n",
    "        cv.rectangle(frame, (x, y), (x+w, y+h), color, 2)\r\n",
    "    cv.imshow(\"frame\",frame)\r\n",
    "\r\n",
    "    if cv.waitKey(1000) == 27:\r\n",
    "        break\r\n",
    "cap.release()\r\n",
    "cv.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit"
  },
  "interpreter": {
   "hash": "a8cad57d2ef24d8bc0f799a33739dcafe360e5d9a85f3c3e1a89d2d1164fbe48"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}